# MapReduce-Database-Management
MapReduce to find the most profitable month for hotel bookings over a period of four years


In this project, we aim to perform big data analytics on hotel booking datasets to gain insights into booking trends and revenue analysis. The datasets consist of booking information from different sources. Our goal is to combine the datasets efficiently, process them using the MapReduce paradigm, and derive meaningful conclusions.

## Environment and Hadoop setup Hardware - Ubuntu 22.04 System Software -
1) Java 8 - We first installed the Java 8 version of jdk from the Oracle website.
2) Hadoop 3.2.1 - we set up the Hadoop environment on Windows WSL on Ubuntu System.
3) Install ssh
   
## Instructions to execute the project:
1) Start ssh service
Command: sudo service ssh restart
2) Start all hadoop services Command: start-all.sh
3) Create a directory in hadoop Command: hdfs dfs -mkdir /database
4) Put both the datasets set1 and set2 in hadoop
   Command: hdfs dfs -put set1.csv /database Hdfs dfs -put set2.csv /database
5) We compile the DatasetAppend class using java and hadoop and create a DatasetAppend jar file.
Command: javac -classpath $(hadoop classpath) DatasetAppend.java jar cvf DatasetAppend.jar DatasetAppend*.class
6) The folder contains two preprocessed datasets: set1 and set2. We first pass these two datasets as inputs to the DatasetAppend Class and it will create a single merged dataset. This merged dataset is also present in the folder.
Command: hadoop jar DatasetAppend.jar DatasetAppend /database/set1.csv /database/set2.csv /database/combined_data.csv
7) We can retrieve the combined_data.csv file from the hadoop file system as follows. The combined dataset is present in the combined_data folder in part-r-00000.
Command: hadoop fs -get /database/combined_data.csv combined_data
8) We compile the RevenueAnalyzer class using java and hadoop and create a RevenueAnalyzer jar file.
Command: javac -classpath $(hadoop classpath) RevenueAnalyzer.java
jar cvf RevenueAnalyzer.jar RevenueAnalyzer*.class
9) We pass the output of the first MapReduce job (DatasetAppend class) to the second
MapReduce job (RevenueAnalyzer class).
Command: hadoop jar RevenueAnalyzer.jar RevenueAnalyzer /database/combined_data.csv/part-r-00000 /database/revenue_sorted.csv
10) We can retrieve the output file from the hadoop file system as follows: Command: hadoop fs -get /database/revenue_sorted.csv revenue_sorted
11) The output shows the rankings, popular months by year and the most popular month among all four years. This result is present in the file part-r-00000 in the revenue_sorted folder. You can open it using vscode.


## Data Preprocessing:
Before applying MapReduce, we performed data preprocessing on the original datasets on google colab. This made it easier to merge the two datasets together in the mapreduce phase. The preprocessing steps were as follows:
1. Dropping the unnecessary columns which are not required for the calculation of total revenue or present in only one of the datasets.
2. Converting the booking status and arrival month columns to a consistent format across both datasets. We did this for the month columns and booking_status columns. This ensured compatibility and accuracy during subsequent MapReduce operations.

## First MapReduce Job: Dataset Append
To combine the two datasets efficiently, we implemented the first MapReduce job called "Dataset Append." The purpose of this job was to merge the records from both datasets into a single dataset. The code for this job was implemented in the DatasetAppend class, which consisted of the AppendMapper and AppendReducer classes.
1. AppendMapper: The mapper sets the entire line as output value and saves it temporarily with a constant key. It then emits each record with a constant key.
2. AppendReducer: The reducer collects and concatenates the records into a merged dataset. It emits the output with an empty key and original value to combine the two datasets.


## Second MapReduce Job: Revenue Analyzer
The second MapReduce job, named "Revenue Analyzer," focused on analyzing the revenue generated by the merged dataset and determining the most popular month for bookings based on revenue. This job was designed to provide insights into booking trends and revenue patterns. The code for this job was implemented in the RevenueAnalyzer class, which included the RevenueMapper and RevenueReducer classes.
1. RevenueMapper: The RevenueMapper parses each input record, calculates the total revenue based on the provided formula. If the booking_status is not 1 which means the booking was not canceled it calculated the total revenue as total bookings * the average price. It then emitted the year and month as the key, with the revenue as the value.
2. RevenueReducer: The RevenueReducer received the revenue values for each year and month, ranked them in descending order using a TreeMap, and stored the maximum revenue values for each year and the overall maximum revenue value. The results included the ranked revenue values, the months with the highest revenue for each year, and the overall most profitable year and month.

